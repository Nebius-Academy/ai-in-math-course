{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb9nuh1nyOBp"
   },
   "source": [
    "# HOMEWORK 6 (10 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jUo58Bj0p0x"
   },
   "source": [
    "# Before we start: a few words about LLM-assisted coding\n",
    "\n",
    "LLMs are great coding helpers, but as any assistants, they need supervision. After all, however much you rely on LLMs for coding, you are responsible for the result.\n",
    "\n",
    "To help you a bit, we share some ideas that might improve your experience with LLMs.\n",
    "\n",
    "**Vibe coding guidelines**\n",
    "\n",
    "We'd recommend trying **Anthropic Claude 3.7 Sonnet**, or **ChatGPT o3/o4-mini**, or **Gemini 2.5** - they'll give you the best result. **DeepSeek V3** or **R1** should also work well. A **playground** is a better vibe coding interface than an API, especially because you'll likely need several iterations to polish the code. Unless you use an AI-powered IDE such as **Cursor**, of course.\n",
    "\n",
    "Here are some general prompting guidelines for LLM-assisted coding:\n",
    "\n",
    "1. **Clearly explain which functionality and interface you need**\n",
    "\n",
    "  \"I need a chatbot\" is too vague, and the results will be unpredictable. Describe how the user will be interacting with the chatbot. Explain which parameters to set up in the constructor. Choose whether you want a function or a class and clearly communicate this. Decide how exceptions should be treated.\n",
    "\n",
    "  Some of the LLMs will be all too earger to create many things you don't ask them - a productionalizing framework, a chatbot factory, examples of usage etc. Without proper guidance, they can swamp you in code. To avoid this, you may add very insistently that you only want the chatbot class/function and nothing else.\n",
    "\n",
    "  Since we're working in Jupyter, LLMs may annoy you much by creating usage examples that require command line execution. Explaining how you are going to work with the code might help with that.\n",
    "\n",
    "2. **Provide code examples**\n",
    "\n",
    "  If you're ok with the design of `answer_with_llm` and if you want the new class or function to have a similar interface, provide its implementation. LLMs are usually good at reproducing design patterns.\n",
    "\n",
    "  It's a good practice to highlight code with\n",
    "\n",
    "  ````{verbatim}\n",
    "  ```\n",
    "  <your code>\n",
    "  ```\n",
    "  ````\n",
    "\n",
    "3. **Test LLM's understanding**\n",
    "\n",
    "  I personally like requesting an LLM to ask any questions it had BEFORE (yes, caps won't hurt) it starts generating code. This might help you to steer the LLM into the right direction. From our experience LLMs sometimes ask really good questions here, uncovering things we'd forgotten to think of beforehand.\n",
    "\n",
    "4. **Be ready for several iterations of improvement**\n",
    "\n",
    "  Even if you prompt an LLM really carefully, it may still surprise you. So, though in this task you may grab the first working version, we advise you not to rely blindly on whatever LLMs generate, especially in longer projects, where programming antipatterns might cost you dearly.\n",
    "\n",
    "  From our experience LLMs are reasonably good at writing boilerplate code, but look out for code duplication, hardcoding, and overcomplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5QALIHlES14"
   },
   "source": [
    "# Setting things up\n",
    "\n",
    "Before starting to work, save your Nebius AI Studio API key to a file called `nebius_api_key` (use plain text editor for that to avoid adding rogue characters) and load it to colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqCgRtIRIcN3"
   },
   "outputs": [],
   "source": [
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRpRGdl5IdJZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(\"nebius_api_key\", \"r\") as file:\n",
    "    nebius_api_key = file.read().strip()\n",
    "\n",
    "os.environ[\"NEBIUS_API_KEY\"] = nebius_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ElsBJ68uacB"
   },
   "source": [
    "We'll be calling APIs quite often in this notebook, so let's define a shortcut fuction to avoid repeating all the code. Also, we'll prettify the output in such a way that it can be viewed without scrolling right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTlC-5omIVOO"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Nebius uses the same OpenAI() class, but with additional details\n",
    "nebius_client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
    "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
    ")\n",
    "\n",
    "llama_8b_model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "def prettify_string(text, max_line_length=80):\n",
    "    \"\"\"Prints a string with line breaks at spaces to prevent horizontal scrolling.\n",
    "\n",
    "    Args:\n",
    "        text: The string to print.\n",
    "        max_line_length: The maximum length of each line.\n",
    "    \"\"\"\n",
    "\n",
    "    output_lines = []\n",
    "    lines = text.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        current_line = \"\"\n",
    "        words = line.split()\n",
    "        for word in words:\n",
    "            if len(current_line) + len(word) + 1 <= max_line_length:\n",
    "                current_line += word + \" \"\n",
    "            else:\n",
    "                output_lines.append(current_line.strip())\n",
    "                current_line = word + \" \"\n",
    "        output_lines.append(current_line.strip())  # Append the last line\n",
    "    return \"\\n\".join(output_lines)\n",
    "\n",
    "def answer_with_llm(prompt: str,\n",
    "                    system_prompt=\"You are a helpful assistant\",\n",
    "                    max_tokens=512,\n",
    "                    client=nebius_client,\n",
    "                    model=llama_8b_model,\n",
    "                    prettify=True,\n",
    "                    temperature=0.7) -> str:\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    if system_prompt:\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            }\n",
    "        )\n",
    "\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    if prettify:\n",
    "        return prettify_string(completion.choices[0].message.content)\n",
    "    else:\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BeC0op9fD1x"
   },
   "source": [
    "## Task 1. Benchmarking LLMs on GSM8k (5 points)\n",
    "\n",
    "In this task, you'll benchmark several LLMs against the [GSM8k](https://huggingface.co/datasets/openai/gsm8k) dataset. It contains grade school math problems which should be reatively easy for the LLMs (or not?).\n",
    "\n",
    "To start with, let's download the dataset and check several problems from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11661,
     "status": "ok",
     "timestamp": 1747744916931,
     "user": {
      "displayName": "Stanislav Fedotov",
      "userId": "11530214105785176141"
     },
     "user_tz": -60
    },
    "id": "flVngDE5Ig8M",
    "outputId": "4478a65b-c740-43c0-867b-62c1eadff1d1"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301,
     "referenced_widgets": [
      "b1459b0f2a5144be9478f8fef8cd16d8",
      "3a513452065049da8c476b9063d96311",
      "9b71bd02cd8747da92c8abb41e9d2d6c",
      "1b82e36f467a4131b00a91073c997e4e",
      "50123fe0021b42728b330741126941dd",
      "ab114eb4f47441a49010bc545b4c3d67",
      "0e9395b0a4f944c2b744439deed9e30b",
      "81f39d0a71a14864a20076db8785f88b",
      "e79a9a9b836a4fba896d3828199d6a44",
      "5bcf70f8813b4882be38d9dd240d741c",
      "35b36b8e070c48db922dfd53d1c8dfd4",
      "c4b847ab5cb3447c82e24ee9d12dc6f5",
      "a83b2da309504781b7c5b4a3711f0444",
      "4e3d024bbde240189b265f37fcb352a5",
      "45e74db53eba4063806d98a52be3163d",
      "bc822cef8ecf460ca9e080a326a71db7",
      "ed86c9f51519433389a003a887ea5e0d",
      "b692090c3be54d55bd871566f27ceee3",
      "c64745aa478c4618903313cfe563c051",
      "2cb6c866b7634e9aaf6c4e3c85e643e2",
      "f18a58d42f25407eb5f3edeb21150733",
      "d687ccd06e5c4babb10138c15a20a8ba",
      "4658e51a397a48d0951e144c0d9c90a3",
      "260f3f922c554114b3031c00dda860dd",
      "db7eaa92074e4b8db150234795d51ba1",
      "9e5a936f02364bafabfdc2f28c5a1222",
      "54c9a41b988049a496157ba596feda67",
      "c61ff3db324d4fdf805de5f75eaf3dcf",
      "db5bf863553f4afd8603f24d8dc6731b",
      "39078edd1f6a4e969e75d800e5d24f6d",
      "2c9d13005d764fa594e199116789c91d",
      "820ef5fe3cce46c29364436345573e83",
      "ce83c7dc73d5419298e35fe2746a36fb",
      "2c1c1cc4bb014e048e41ea5d52a22a28",
      "6c917eb11e594400b48195aecf2d23e3",
      "b01de468482748b88391c04b51635a0a",
      "91aa0b29d89d4a2881d0b7741fdfb463",
      "37bc5deac57546d4b5c26718b69b5577",
      "1138166aaf0a47d6a267c3f40ff13d38",
      "90ce1781b5da457ba2b826f72a9f7dde",
      "66a9622b051d40678156c07d04ad80e4",
      "3bbb448d46e14b19b720fc2e0dfb9f74",
      "323c3bfa4a7c4a78b6e35797b0d48a84",
      "65a615aa9d9745dd95b02cdaabc69562",
      "38b49ef367cb4b3e923428a894b160ff",
      "adda78e8dfb74406a7bfab619cd61145",
      "51215db9a60c4af79d131959a0ad0cfd",
      "f598e122567d4fe19fde0b0534879d51",
      "07c42445d385438a90c6b0dbd06d07e6",
      "c42b79a8a2594e008e2f22cb3272ee67",
      "9a53c4a1c0ed41e092157201762aa97d",
      "92c59b11c8e447f498ec690349e3a760",
      "cb35c4eaa7154528908022ff0792b699",
      "5222e872761247eca0bd5d80690031bc",
      "307c60a825a341f582ea26f96090031a"
     ]
    },
    "executionInfo": {
     "elapsed": 9738,
     "status": "ok",
     "timestamp": 1747744926672,
     "user": {
      "displayName": "Stanislav Fedotov",
      "userId": "11530214105785176141"
     },
     "user_tz": -60
    },
    "id": "-7TE_gUFIH8m",
    "outputId": "40828700-8dc0-402a-d172-005dd7c2bb73"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"openai/gsm8k\", \"main\", cache_dir=\"./gsm8k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1747744926698,
     "user": {
      "displayName": "Stanislav Fedotov",
      "userId": "11530214105785176141"
     },
     "user_tz": -60
    },
    "id": "kJpOQw6lKIff",
    "outputId": "4fac0ef3-f3ad-4440-d7ae-6eacc104a169"
   },
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print(\"Dataset structure:\", dataset)\n",
    "print(\"Available splits:\", list(dataset.keys()))\n",
    "print(\"Train examples:\", len(dataset['train']))\n",
    "print(\"Test examples:\", len(dataset['test']))\n",
    "\n",
    "# Look at the first example\n",
    "example = dataset['train'][0]\n",
    "print(\"\\n--- Example Problem ---\")\n",
    "print(\"Question:\", example['question'])\n",
    "print(\"\\nAnswer:\", example['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0hsCkNZ8nt6"
   },
   "source": [
    "Your task will be to create an `GSM8KEvaluator` class with the following interface:\n",
    "\n",
    "* `__init__` loads the test split of the dataset\n",
    "* `run_evaluation(self, client, model, n, n_questions)` tests a model `model` offered by a client `client` on the dataset, calculating:\n",
    "  \n",
    "  * Accuracy - (number of problems on which the LLM arrives at a correct answer) / 30\n",
    "  * Average execution time (seconds per problem)\n",
    "  * Average solution length in tokens\n",
    "\n",
    "  The `n` parameter is the number of **Self consistency** passes: for each problem, you'll need to get `n` solutions and choose the most popular answer for evaluation. We suggest using the parameter `n` in\n",
    "\n",
    "  ```\n",
    "  client.chat.completions.create(\n",
    "                messages,\n",
    "                model=model,\n",
    "                n=n\n",
    "            )\n",
    "  ```\n",
    "\n",
    "  The `n_questions` parameter determines how many first questions to score with a model. Don't take `n_questions` more than 50 to save time and money.\n",
    "\n",
    "You can draw inspiration from the `MMLUEvaluator` class implemented [here](https://colab.research.google.com/github/Nebius-Academy/LLM-Engineering-Essentials/blob/main/topic1/1.5_how_to_choose_an_llm.ipynb).\n",
    "\n",
    "Test at least three LLMs **on the first 50 problems from the test split** - we'd suggest trying one small (4-8B parameters), one medium (30-70B parameters) and one huge (>200B parameters) model. Run them with `n = 1, 5`. Compare the accuracy.\n",
    "\n",
    "**Hints and suggestions**\n",
    "\n",
    "0. Note that you'll need to extract the correct answer from the solution. Luckily, it should be quite easy to do.\n",
    "1. Be careful with parsing the LLM's answer - wrong parsing can greatly worsen the results\n",
    "2. Be careful with the `max_tokens` parameter - if you set it too low, the solutions might get cut short, especially with larger models and especially with long reasoning ones.\n",
    "3. I'd avoid **DeepSeek R1** for this task. Luckily, **Qwen 3** models are also reasoning, and they are much smaller.\n",
    "4. Use `tqdm` to create evaluation progress bars. Watching a progress bar moving is reassuring, especially for larger models that work for longer time.\n",
    "5. Log all the model answers and return them together with metrics. Start with `n_questions=3` or something like that to debug your evaluator (and especially your parsing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zxQhy3IwzWKO"
   },
   "outputs": [],
   "source": [
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IM02EH_1dxJ"
   },
   "source": [
    "## Task 2. Mapping LLM \"thoughts\" (5 points)\n",
    "\n",
    "In this task, we'll look closer at \"thinking patters\" of LLMs:\n",
    "\n",
    "- We'll look closer at an LLM's \"tree of thoughts\",\n",
    "- We'll investigate how long the typical thoughts are,\n",
    "- We'll explore the \"underthinking\" phenomenon.\n",
    "\n",
    "If you encounter any difficulties or simply want to see our solutions, feel free to check the [Solutions notebook](https://colab.research.google.com/github/Nebius-Academy/LLM-Engineering-Essentials/blob/main/topic2/r.1_intro_to_llm_reasoning.ipynb).\n",
    "\n",
    "To have something to experiment with, we'll run evaluation of **QwQ-32B-Preview** on a subset of [MATH benchmark](https://huggingface.co/datasets/nlile/hendrycks-MATH-benchmark). This benchmark is relatively challenging, but to a reasonable extent. It's not [FrontierMath](https://epoch.ai/frontiermath) :)\n",
    "\n",
    "We'll take the first 50 problems that satisfy two following conditions:\n",
    "\n",
    "- Their answer is either straightforwardly converted to `float`, or it's a simple Latex-formatted fraction, like `\\frac{2}{3}`.\n",
    "- Their \"level\" is either 4 ot 5 (more challenge!).\n",
    "\n",
    "**Note** You can use **deepseek-ai/DeepSeek-R1**, if you want, but it will generate solutions *very* slowly (not mentioning the cost).\n",
    "\n",
    "Also, if you don't want to run the evaluation of **QWQ** on your own, you may download the `qwq_results.pkl` file from Google drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPEXmWjW2TNN"
   },
   "outputs": [],
   "source": [
    "!gdown 1_hEX_h7fj6FXH3lG5AMthJjiK1JwAU9J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eQXrlRi9Cj9"
   },
   "source": [
    "### Evaluating QWQ on MATH Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V62K3KmJ7sNm"
   },
   "source": [
    "If you're in, let's create the evaluator. And we'll start by data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQL9RmxsYRSy"
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301,
     "referenced_widgets": [
      "08290a5b60d143b488b695b28ec4cf7b",
      "d2dc377c48314c3d90f6b95e1a399201",
      "3999b57df33947cba2cea4a5d72544d2",
      "283951f6a7844517adbf305ce1e55065",
      "bd84331098e74381b58950e0079806c9",
      "91e0d6e3f9ce4966b7dd298f29d86b65",
      "5b62c0b8b32f4663ab4643471d89b118",
      "e4d414af01284d819eae709308e7c1ed",
      "f3811d9ca4384838855be689dcf77f3e",
      "9c88a4aee74944319981e0dd6c20fbf3",
      "9e917e87c0964bb88550359ab2b85199",
      "285079aefc9b45fb84d84e33d54a0753",
      "211aa6eccf8748a78727737d9a4b4825",
      "a2cf26d976e5472c9b0d5efdeeaf4da4",
      "98cc43bf15db48508fea44511adabb38",
      "6a680918007041b795e405f20c52eb3a",
      "8a76de86f9354b64bb09e6af9aaa5384",
      "e8604c29516d4e3088a029b5a12f95ae",
      "367d44263c804e00b722a2985d29176a",
      "62ad901188b248049a223def7e468e69",
      "163e63c6fa69441888440b76cf4cac68",
      "3c61fb0f1ffb49c397fcdd4d10f81ab1",
      "4a660d1607124e14bb18d2f55fdcc95d",
      "c2d4b9cc62d24c1aacc96c6e22dfca38",
      "71850518216e4ae5802205a431ffa0b8",
      "9d30b71faf554c1492f1fd34cb1a8f20",
      "2350dc8cfac142be804dae488ae5732e",
      "c0f66051c0a8433aa63289dd2bf4f09a",
      "3920a2c4675b4ae6aba4938d18dafac9",
      "768b2fd64ad7420ea6ecf168b7f667d3",
      "cd2fba06d8d442b78385c3d7f53fa0f4",
      "1de71401cd0a4ffdb3aca67c1b154ff5",
      "1c434affde874eca923fedfc279724d8",
      "8474d17ca8664245a69ed6af3b31e3bb",
      "233b6d7e315c4695928abbd7b64c3b0f",
      "9738d2d5c7a0404684fd4204b040a095",
      "6c3943309db4488cae42c7fdc4cf818d",
      "f470e7e63d4d41e5a7da86ef96e17981",
      "20196e3c7a534b43b854eb130a99a59f",
      "119eb34a104f45e0807845e5ddb015fc",
      "6a04189aa0ec47418781abe13db40372",
      "90a485648fd245f2915122178d21420e",
      "b13bfd1948874c7da8dbb05b3caf57a4",
      "823ee73aae8543d381852b5a1efe353b",
      "8c6d07416e7f4c369520ecad551630a3",
      "3e350760917c4c92a4e5481fda928ce6",
      "1694547865e841678e63d302df12dc9d",
      "c995e26f43d244c28485677d5d23cf68",
      "861f533c31e341b6b6f9234baa26fc05",
      "9d4e1ec922c5453db15a1c0ae25a00c9",
      "374365c8468e48cea9da032a44bec48f",
      "9512b6d6f45842e5986f3e59d890ea00",
      "4e359dd0ede0421fbdc2dbd4e5abab8c",
      "2df081a628344dd6aff766aaad3a1a90",
      "5916f3e3a3fb4cfaac3e13615a304ae1"
     ]
    },
    "executionInfo": {
     "elapsed": 4216,
     "status": "ok",
     "timestamp": 1740929846243,
     "user": {
      "displayName": "Stanislav Fedotov",
      "userId": "11530214105785176141"
     },
     "user_tz": 0
    },
    "id": "E7B4oUe6YRVL",
    "outputId": "bcd67685-3765-49d4-bda4-0da7ea15720f"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset('nlile/hendrycks-MATH-benchmark', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1740929850376,
     "user": {
      "displayName": "Stanislav Fedotov",
      "userId": "11530214105785176141"
     },
     "user_tz": 0
    },
    "id": "vyOS3mGNYmKu",
    "outputId": "bb5f4aeb-f7dd-464b-af5a-7ce0f902e58a"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def conver_string_to_number(s):\n",
    "    \"\"\"\n",
    "    Checks if a string is a number or a fraction and computes the fraction if applicable.\n",
    "\n",
    "    Args:\n",
    "        s: The input string.\n",
    "\n",
    "    Returns:\n",
    "        A float representing the number or fraction, or None if the string is invalid.\n",
    "    \"\"\"\n",
    "    if \"_\" in s:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        return float(s)  # Try converting to a float directly\n",
    "    except ValueError:\n",
    "        match = re.match(r\"\\\\frac\\{(\\d+)\\}\\{(\\d+)\\}\", s)\n",
    "        if match:\n",
    "            numerator = int(match.group(1))\n",
    "            denominator = int(match.group(2))\n",
    "            if denominator != 0:\n",
    "                return numerator / denominator\n",
    "            else:\n",
    "                return None  # Handle division by zero\n",
    "        else:\n",
    "            return None  # String is not a number or a valid fraction\n",
    "\n",
    "# Example usage\n",
    "strings = [\"123\", \"\\\\frac{1}{2}\", \"\\\\frac{3}{0}\", \"abc\", \"\\\\frac{4}{5}\"]\n",
    "for s in strings:\n",
    "    result = conver_string_to_number(s)\n",
    "    if result is not None:\n",
    "        print(f\"'{s}' is a valid number or fraction. Result: {result}\")\n",
    "    else:\n",
    "        print(f\"'{s}' is not a valid number or fraction.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1740929852667,
     "user": {
      "displayName": "Stanislav Fedotov",
      "userId": "11530214105785176141"
     },
     "user_tz": 0
    },
    "id": "2W93rs6iY8_u",
    "outputId": "e5f9e69e-6349-456f-de51-f9b1d65f1bf2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame(ds)\n",
    "\n",
    "df['num_answer'] = df['answer'].apply(conver_string_to_number)\n",
    "df['valid_answer'] = df['num_answer'].notna()\n",
    "\n",
    "# Select the first 50 rows where the 'answer' column passes the check\n",
    "selected_rows = df[(df['valid_answer']) & (df['level'] >= 4)].head(50)\n",
    "selected_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1Bz-QEP8GO8"
   },
   "source": [
    "The evaluator itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFgDjWzaaAUa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "def find_boxed_content(text):\n",
    "    matches = re.findall(r\"boxed\\{(.*?)\\}\", text)\n",
    "    try:\n",
    "        return conver_string_to_number(matches[-1])\n",
    "    except:\n",
    "        try:\n",
    "            return conver_string_to_number(text.split(\"\\n\")[-1].split(\" \")[-1].strip(\".;$\"))\n",
    "        except:\n",
    "            print(f\"\"\"Wrong format in:\n",
    "                {text.split()[-1]}\"\"\")\n",
    "            return None\n",
    "\n",
    "class MATHEvaluator:\n",
    "    def __init__(self, system_prompt: str = \"You are a helpful assistant.\",\n",
    "                 prompt: str = None):\n",
    "        \"\"\"\n",
    "        Initialize the MATH evaluator.\n",
    "\n",
    "        Args:\n",
    "            system_prompt: Optional system prompt for the model\n",
    "            prompt: Custom prompt for the model\n",
    "        \"\"\"\n",
    "\n",
    "        self.system_prompt = system_prompt\n",
    "\n",
    "        self.prompt = \"\"\"{question}\"\"\"\n",
    "\n",
    "        self.questions, self.answers = selected_rows[\"problem\"].to_list(), selected_rows[\"num_answer\"].to_list()\n",
    "\n",
    "    def extract_answer(self, solution: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract the letter answer from model's response.\n",
    "\n",
    "        Args:\n",
    "            response: Raw model response\n",
    "\n",
    "        Returns:\n",
    "            Extracted answer (an float)\n",
    "        \"\"\"\n",
    "        # Look for a single letter answer in the response\n",
    "        try:\n",
    "            # answer = float(solution.split(\"\\n\").split(\" \")[1].strip(\".;)\"))\n",
    "            answer = find_boxed_content(solution)\n",
    "        except:\n",
    "            answer = None\n",
    "        # print(solution.split(\"\\n\")[-1])\n",
    "        # print(answer)\n",
    "        return answer\n",
    "\n",
    "    def evaluate_single_question(self, question: str,\n",
    "                                 correct_answer: float,\n",
    "                                 client, model, max_tokens,\n",
    "                                 temperature=None) -> Tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Evaluate a single question.\n",
    "\n",
    "        Args:\n",
    "            question: Formatted question string\n",
    "            correct_answer: Correct answer letter\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (is_correct, extracted_answer, model_response)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            model_response = answer_with_llm(\n",
    "                prompt=self.prompt.format(\n",
    "                    question=question\n",
    "                ),\n",
    "                client=client, model=model,\n",
    "                system_prompt=self.system_prompt,\n",
    "                max_tokens=max_tokens\n",
    "            )\n",
    "            answer = self.extract_answer(model_response)\n",
    "            if answer:\n",
    "                is_correct = np.abs(answer - correct_answer) < 1e-10\n",
    "            else:\n",
    "                is_correct = False\n",
    "            return is_correct, answer, model_response\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating question: {e}\")\n",
    "            return False, None, None\n",
    "\n",
    "    def run_evaluation(self, client : OpenAI, model : str,\n",
    "                       n_questions=50, max_tokens=8192, temperature=0.) -> Dict:\n",
    "        \"\"\"\n",
    "        Run evaluation of a given model on the first n_questions.\n",
    "\n",
    "        Args:\n",
    "            client: Which client to use (OpenAI or Nebius)\n",
    "            model: Which model to use\n",
    "            n_questions: How many first questions to take\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with evaluation metrics\n",
    "        \"\"\"\n",
    "        evaluation_log = []\n",
    "        correct_count = 0\n",
    "        correct_format_count = 0\n",
    "        if n_questions:\n",
    "            n_questions = min(n_questions, len(self.questions))\n",
    "        else:\n",
    "            n_questions = len(self.questions)\n",
    "\n",
    "        for i in tqdm(range(n_questions)):\n",
    "            is_correct, answer, model_response = self.evaluate_single_question(\n",
    "                question=self.questions[i],\n",
    "                correct_answer=self.answers[i],\n",
    "                client=client,\n",
    "                model=model,\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temperature\n",
    "            )\n",
    "\n",
    "            if answer:\n",
    "                correct_format_count += 1\n",
    "\n",
    "            if is_correct:\n",
    "                correct_count += 1\n",
    "\n",
    "            evaluation_log.append({\n",
    "                'answer': answer,\n",
    "                'correct_format': not answer is None,\n",
    "                'model_response': model_response,\n",
    "                'is_correct': is_correct\n",
    "            })\n",
    "\n",
    "        accuracy = correct_count / n_questions\n",
    "        format_correctness = correct_format_count / n_questions\n",
    "        evaluation_results = {\n",
    "            'accuracy': accuracy,\n",
    "            'format_correctness': format_correctness,\n",
    "            'evaluation_log': evaluation_log\n",
    "        }\n",
    "\n",
    "        return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfXAPAXYargI"
   },
   "outputs": [],
   "source": [
    "math_evaluator = MATHEvaluator(system_prompt=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1971550,
     "status": "ok",
     "timestamp": 1740932096406,
     "user": {
      "displayName": "Stanislav Fedotov",
      "userId": "11530214105785176141"
     },
     "user_tz": 0
    },
    "id": "ZiUM6YL3argI",
    "outputId": "9cbabbac-0e49-46a4-adfb-581e1f1c0da0"
   },
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
    "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
    ")\n",
    "\n",
    "qwq_results = math_evaluator.run_evaluation(\n",
    "    client=client,\n",
    "    model=\"Qwen/QwQ-32B-Preview\",\n",
    "    n_questions=None,\n",
    "    max_tokens=None\n",
    ")\n",
    "print(f'\\nAccuracy: {deepseek_results[\"accuracy\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRqbf9bS7-u1"
   },
   "source": [
    "Let's save the results to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cs3xQLmco9JQ"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(qwq_results, open(\"qwq_results.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvsrI3l3Ye6v"
   },
   "source": [
    "Now, you can load the file even if you didn't create it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5794,
     "status": "ok",
     "timestamp": 1741150220656,
     "user": {
      "displayName": "Stanislav Fedotov",
      "userId": "11530214105785176141"
     },
     "user_tz": 0
    },
    "id": "WNDZKkWco9Tb",
    "outputId": "ae58e7e5-e644-4f1b-a354-c07e7ffaa61f"
   },
   "outputs": [],
   "source": [
    "!gdown 1_hEX_h7fj6FXH3lG5AMthJjiK1JwAU9J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwMw22w-79BJ"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "qwq_results = pickle.load(open(\"qwq_results.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swHTNC7g79Ji"
   },
   "source": [
    "### Analyzing thoughts\n",
    "\n",
    "We've prepared quite a large thought analysis and visualization script; so we decided not to include it here (please check it in github if you're curious). Here, we'll only download and import it from `thought_analysis.py`.\n",
    "\n",
    "A few words about what's happening in `thought_analysis.py`:\n",
    "\n",
    "- First of all, if the solution has `<think>...</think>` markup inside, only the fragment between them is extracted. (We're only interested in the \"internal\" thinking process.)\n",
    "- Then, solutions are divided into individial \"thoughts\" using the following heuristics:\n",
    "  - `Alternatively`, `Wait`, `But wait`, `But let me check again`, `But let's verify`, and similar phrases mark the starts of new \"thoughts\". Note that they are typical indications of backtracking and solution branching. There may be more, of course.\n",
    "  - Otherwise, a \"thought\" is a continuous range of paragraphs of length not less than `min_split_size` characters (we'll take `min_split_size=120`). Separate-line Latex formulas are always added to the previous thought.\n",
    "- For each \"thought\", its length in tokens is calculated. For that, we need to supply the right **tokenizer** which corresponds to the model which generated the solutions - in our case, **[QwQ-32B-Preview](https://huggingface.co/Qwen/QwQ-32B-Preview)**. And that's why you needed to create a **Hugging Face access token**. If you haven't done it yet, please register to HF, get the token and load it to colab in a `hf_access_token` file.\n",
    "\n",
    "  If you're ardently against registering to Hugging Face, you can supply `None` as `tokenizer`, but in this case you won't get correct token length of individual \"thoughts\".\n",
    "\n",
    "- The **\"thee of thoughts\"** is constructed in the following way:\n",
    "  - If a \"thought\" starts with `Alternatively`, `Wait`, or `But wait`, we query using another LLM (**Llama-3.1-70B** by default) to determine which of the previous \"thoughts\" is continued by this. If it starts a completely different solution, the thought is connected to **root** (empty solution; the very start).\n",
    "  - Otherwise, the thought is connected with the previous one.\n",
    "\n",
    "- Finally, the tree is saved as `thought_analysis/thought_tree.png`, if you didn't change default output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2yGX-XD47Av"
   },
   "outputs": [],
   "source": [
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1741611770789,
     "user": {
      "displayName": "Stanislav Fedotov",
      "userId": "11530214105785176141"
     },
     "user_tz": 0
    },
    "id": "hMu58cxChOMI",
    "outputId": "636718d0-c71d-46cc-b12d-c47bfb379627"
   },
   "outputs": [],
   "source": [
    "!curl -o thought_analysis.py https://raw.githubusercontent.com/Nebius-Academy/LLM-Engineering-Essentials/main/topic2/thought_analysis.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwS4qdLbtB15"
   },
   "source": [
    "Let's also download a sample solution for us to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1741611771203,
     "user": {
      "displayName": "Stanislav Fedotov",
      "userId": "11530214105785176141"
     },
     "user_tz": 0
    },
    "id": "s2GczUGFtFCb",
    "outputId": "caf46b29-0c52-4bca-b340-f7a37f99a5b5"
   },
   "outputs": [],
   "source": [
    "!curl -o sample_solution.txt https://raw.githubusercontent.com/Nebius-Academy/LLM-Engineering-Essentials/main/topic2/sample_solution.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12112,
     "status": "ok",
     "timestamp": 1741611893167,
     "user": {
      "displayName": "Stanislav Fedotov",
      "userId": "11530214105785176141"
     },
     "user_tz": 0
    },
    "id": "CdZTfNwlhOO5",
    "outputId": "65a52aaa-183f-48a4-f6ca-8bc54ea6d75c"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from thought_analysis import analyze_solution_thoughts\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "with open(\"hf_access_token\", \"r\") as file:\n",
    "    hf_access_token = file.read().strip()\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
    "    api_key=os.environ.get(\"NEBIUS_API_KEY\")\n",
    ")\n",
    "model = \"meta-llama/Meta-Llama-3.1-70B-Instruct\"\n",
    "\n",
    "reasoning_model = \"deepseek-ai/DeepSeek-R1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(reasoning_model,\n",
    "                                          hf_access_token=hf_access_token)\n",
    "\n",
    "file_path = \"sample_solution.txt\"  # Path to the solution file\n",
    "output_dir = \"thought_analysis\"  # Directory to save results\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    solution_text = file.read()\n",
    "\n",
    "\n",
    "connections, viz_path, summary_path = analyze_solution_thoughts(\n",
    "    solution_text,\n",
    "    client=client,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    output_dir=output_dir,\n",
    "    min_split_size=120\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVzi-kxRwewD"
   },
   "source": [
    "We can look closely at the connection or just check the `.png` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1741152080946,
     "user": {
      "displayName": "Stanislav Fedotov",
      "userId": "11530214105785176141"
     },
     "user_tz": 0
    },
    "id": "cZy8RQHFhOR9",
    "outputId": "d363b028-2767-4850-ac1a-e249c7ee1489"
   },
   "outputs": [],
   "source": [
    "connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ti9CFYW7E1dU"
   },
   "source": [
    "**Your task**. Take some other solutions, construct their trees of thoughts.\n",
    "\n",
    "You may also play with solutions generated by **DeepSeek R1**. We created several of them for you:\n",
    "\n",
    "- 10 from the MATH benchmark,\n",
    "- 10 from the AIME benchmark,\n",
    "- 2 from the Frontier Math benchmark.\n",
    "\n",
    "Just beware that these solutions will be much, much longer than the solutions by **QWQ**.\n",
    "\n",
    "You can download them, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5360,
     "status": "ok",
     "timestamp": 1741152272768,
     "user": {
      "displayName": "Stanislav Fedotov",
      "userId": "11530214105785176141"
     },
     "user_tz": 0
    },
    "id": "5C8tZJtNhOU_",
    "outputId": "003239cd-2d12-4ac2-c5c5-7e957fdac641"
   },
   "outputs": [],
   "source": [
    "!gdown 1TpROB-8XAE6z1OlTfli7XB6YoY6WQi18\n",
    "!unzip deepseek_solutions.zip -d deepseek_solutions/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMVuGm5OFdKs"
   },
   "source": [
    "And, of course, feel free to create your own solutions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7flUkBQFlXb"
   },
   "source": [
    "### Size of Branches of Thoughts\n",
    "\n",
    "**This is a task for you**! Create a simplified fuction\n",
    "\n",
    "```\n",
    "thoughts, token_counts = decompose_solution_thoughts(sample_text,\n",
    "                                                     tokenizer=tokenizer)\n",
    "```\n",
    "\n",
    "that, given a solution `sample_text` and a tokenizer, returns:\n",
    "\n",
    "- `thoughts` which is a split of `sample_text` by exactly `Alternatively`, `Wait`, `But wait` (you may add some of their synonyms you'll spot in the solutions). So, we only keep track of the **whole branches of the \"tree of thoughts\"** here.\n",
    "- `token_counts` - the number of tokens in each of these \"branches\".\n",
    "\n",
    "Now, we suggest you to explore the size of these branches in tokens. Create a histogram of branch sizes. What can you say about its shape? Take a look at several extremely long branches - what do you think, why are they so long? Check the shortest branches. What happens there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rE_ao9lNhOX3"
   },
   "outputs": [],
   "source": [
    "# <YOUR EXPERIMENTS HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIpIddZGIS80"
   },
   "source": [
    "### LLM underthinking\n",
    "\n",
    "This part is inspired by [Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs](https://arxiv.org/pdf/2501.18585). This paper investigated connection between the length of thought branches (fragments of solution between \"Alternatively\", \"Wait\", etc) and the solution accuracy. The found out that in many cases LLMs abandon promising solutions, cutting thought branches short before they could come to fruition - and this might contribute to failure of the whole solution.\n",
    "\n",
    "**Your task**: create on one plot two histograms of branch lengths - one histogram for tasks with correct answer and one of tasks with incorrect answer. You can find information about answer correctness in `qwq_results[\"evaluation_log\"]` (`\"is_correct\"` fields).\n",
    "\n",
    "Since there is a different number of correct and incorrect answers in the data, we recommend normalizing the histograms so that they show frequency instead of count. This may be done by setting `density=True`. Do you see any specific patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3xpa5LDKJTj"
   },
   "outputs": [],
   "source": [
    "# <Your experiments here>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1sd9mgimuUJPu1JqxjiEyisOvNFBXg-CK",
     "timestamp": 1755763255427
    },
    {
     "file_id": "1mn1IsPaYVDB_JpSDWo9OKNnNgnckUM62",
     "timestamp": 1747746343012
    },
    {
     "file_id": "1fIhZO8y77cPWwBadGg_DpHQtg6tA7RLH",
     "timestamp": 1747666258455
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07c42445d385438a90c6b0dbd06d07e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e9395b0a4f944c2b744439deed9e30b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1138166aaf0a47d6a267c3f40ff13d38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b82e36f467a4131b00a91073c997e4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bcf70f8813b4882be38d9dd240d741c",
      "placeholder": "​",
      "style": "IPY_MODEL_35b36b8e070c48db922dfd53d1c8dfd4",
      "value": " 7.94k/7.94k [00:00&lt;00:00, 215kB/s]"
     }
    },
    "260f3f922c554114b3031c00dda860dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c61ff3db324d4fdf805de5f75eaf3dcf",
      "placeholder": "​",
      "style": "IPY_MODEL_db5bf863553f4afd8603f24d8dc6731b",
      "value": "test-00000-of-00001.parquet: 100%"
     }
    },
    "2c1c1cc4bb014e048e41ea5d52a22a28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c917eb11e594400b48195aecf2d23e3",
       "IPY_MODEL_b01de468482748b88391c04b51635a0a",
       "IPY_MODEL_91aa0b29d89d4a2881d0b7741fdfb463"
      ],
      "layout": "IPY_MODEL_37bc5deac57546d4b5c26718b69b5577"
     }
    },
    "2c9d13005d764fa594e199116789c91d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2cb6c866b7634e9aaf6c4e3c85e643e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "307c60a825a341f582ea26f96090031a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "323c3bfa4a7c4a78b6e35797b0d48a84": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35b36b8e070c48db922dfd53d1c8dfd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37bc5deac57546d4b5c26718b69b5577": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38b49ef367cb4b3e923428a894b160ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_adda78e8dfb74406a7bfab619cd61145",
       "IPY_MODEL_51215db9a60c4af79d131959a0ad0cfd",
       "IPY_MODEL_f598e122567d4fe19fde0b0534879d51"
      ],
      "layout": "IPY_MODEL_07c42445d385438a90c6b0dbd06d07e6"
     }
    },
    "39078edd1f6a4e969e75d800e5d24f6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a513452065049da8c476b9063d96311": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab114eb4f47441a49010bc545b4c3d67",
      "placeholder": "​",
      "style": "IPY_MODEL_0e9395b0a4f944c2b744439deed9e30b",
      "value": "README.md: 100%"
     }
    },
    "3bbb448d46e14b19b720fc2e0dfb9f74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "45e74db53eba4063806d98a52be3163d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f18a58d42f25407eb5f3edeb21150733",
      "placeholder": "​",
      "style": "IPY_MODEL_d687ccd06e5c4babb10138c15a20a8ba",
      "value": " 2.31M/2.31M [00:00&lt;00:00, 12.8MB/s]"
     }
    },
    "4658e51a397a48d0951e144c0d9c90a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_260f3f922c554114b3031c00dda860dd",
       "IPY_MODEL_db7eaa92074e4b8db150234795d51ba1",
       "IPY_MODEL_9e5a936f02364bafabfdc2f28c5a1222"
      ],
      "layout": "IPY_MODEL_54c9a41b988049a496157ba596feda67"
     }
    },
    "4e3d024bbde240189b265f37fcb352a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c64745aa478c4618903313cfe563c051",
      "max": 2306545,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2cb6c866b7634e9aaf6c4e3c85e643e2",
      "value": 2306545
     }
    },
    "50123fe0021b42728b330741126941dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51215db9a60c4af79d131959a0ad0cfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92c59b11c8e447f498ec690349e3a760",
      "max": 1319,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cb35c4eaa7154528908022ff0792b699",
      "value": 1319
     }
    },
    "5222e872761247eca0bd5d80690031bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54c9a41b988049a496157ba596feda67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bcf70f8813b4882be38d9dd240d741c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65a615aa9d9745dd95b02cdaabc69562": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66a9622b051d40678156c07d04ad80e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c917eb11e594400b48195aecf2d23e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1138166aaf0a47d6a267c3f40ff13d38",
      "placeholder": "​",
      "style": "IPY_MODEL_90ce1781b5da457ba2b826f72a9f7dde",
      "value": "Generating train split: 100%"
     }
    },
    "81f39d0a71a14864a20076db8785f88b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "820ef5fe3cce46c29364436345573e83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90ce1781b5da457ba2b826f72a9f7dde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91aa0b29d89d4a2881d0b7741fdfb463": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_323c3bfa4a7c4a78b6e35797b0d48a84",
      "placeholder": "​",
      "style": "IPY_MODEL_65a615aa9d9745dd95b02cdaabc69562",
      "value": " 7473/7473 [00:00&lt;00:00, 53354.00 examples/s]"
     }
    },
    "92c59b11c8e447f498ec690349e3a760": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a53c4a1c0ed41e092157201762aa97d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b71bd02cd8747da92c8abb41e9d2d6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81f39d0a71a14864a20076db8785f88b",
      "max": 7940,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e79a9a9b836a4fba896d3828199d6a44",
      "value": 7940
     }
    },
    "9e5a936f02364bafabfdc2f28c5a1222": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_820ef5fe3cce46c29364436345573e83",
      "placeholder": "​",
      "style": "IPY_MODEL_ce83c7dc73d5419298e35fe2746a36fb",
      "value": " 419k/419k [00:00&lt;00:00, 20.5MB/s]"
     }
    },
    "a83b2da309504781b7c5b4a3711f0444": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed86c9f51519433389a003a887ea5e0d",
      "placeholder": "​",
      "style": "IPY_MODEL_b692090c3be54d55bd871566f27ceee3",
      "value": "train-00000-of-00001.parquet: 100%"
     }
    },
    "ab114eb4f47441a49010bc545b4c3d67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "adda78e8dfb74406a7bfab619cd61145": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c42b79a8a2594e008e2f22cb3272ee67",
      "placeholder": "​",
      "style": "IPY_MODEL_9a53c4a1c0ed41e092157201762aa97d",
      "value": "Generating test split: 100%"
     }
    },
    "b01de468482748b88391c04b51635a0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66a9622b051d40678156c07d04ad80e4",
      "max": 7473,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3bbb448d46e14b19b720fc2e0dfb9f74",
      "value": 7473
     }
    },
    "b1459b0f2a5144be9478f8fef8cd16d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3a513452065049da8c476b9063d96311",
       "IPY_MODEL_9b71bd02cd8747da92c8abb41e9d2d6c",
       "IPY_MODEL_1b82e36f467a4131b00a91073c997e4e"
      ],
      "layout": "IPY_MODEL_50123fe0021b42728b330741126941dd"
     }
    },
    "b692090c3be54d55bd871566f27ceee3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bc822cef8ecf460ca9e080a326a71db7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c42b79a8a2594e008e2f22cb3272ee67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4b847ab5cb3447c82e24ee9d12dc6f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a83b2da309504781b7c5b4a3711f0444",
       "IPY_MODEL_4e3d024bbde240189b265f37fcb352a5",
       "IPY_MODEL_45e74db53eba4063806d98a52be3163d"
      ],
      "layout": "IPY_MODEL_bc822cef8ecf460ca9e080a326a71db7"
     }
    },
    "c61ff3db324d4fdf805de5f75eaf3dcf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c64745aa478c4618903313cfe563c051": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb35c4eaa7154528908022ff0792b699": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ce83c7dc73d5419298e35fe2746a36fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d687ccd06e5c4babb10138c15a20a8ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db5bf863553f4afd8603f24d8dc6731b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db7eaa92074e4b8db150234795d51ba1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39078edd1f6a4e969e75d800e5d24f6d",
      "max": 419088,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2c9d13005d764fa594e199116789c91d",
      "value": 419088
     }
    },
    "e79a9a9b836a4fba896d3828199d6a44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ed86c9f51519433389a003a887ea5e0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f18a58d42f25407eb5f3edeb21150733": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f598e122567d4fe19fde0b0534879d51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5222e872761247eca0bd5d80690031bc",
      "placeholder": "​",
      "style": "IPY_MODEL_307c60a825a341f582ea26f96090031a",
      "value": " 1319/1319 [00:00&lt;00:00, 45527.98 examples/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
